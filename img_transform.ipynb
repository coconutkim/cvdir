{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src.shape: (356, 493, 3)\n",
      "src.dtype: uint8\n",
      "The pixel value [B, G, R] at (0, 0) is [47 88 50]\n"
     ]
    }
   ],
   "source": [
    "# colorop\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "def color_op():\n",
    "    src = cv2.imread('./img/butterfly.jpg', cv2.IMREAD_COLOR)\n",
    "\n",
    "    if src is None:\n",
    "        print('Image load failed!')\n",
    "        return\n",
    "\n",
    "    print('src.shape:', src.shape)\n",
    "    print('src.dtype:', src.dtype)\n",
    "\n",
    "    # b, g, r = src[0, 0]\n",
    "    print('The pixel value [B, G, R] at (0, 0) is', src[0, 0])\n",
    "\n",
    "\n",
    "def color_inverse():\n",
    "    src = cv2.imread('./img/butterfly.jpg', cv2.IMREAD_COLOR)\n",
    "\n",
    "    if src is None:\n",
    "        print('Image load failed!')\n",
    "        return\n",
    "\n",
    "    dst = np.zeros(src.shape, src.dtype)\n",
    "\n",
    "    for j in range(src.shape[0]):\n",
    "        for i in range(src.shape[1]):\n",
    "            p1 = src[j, i]\n",
    "            p2 = dst[j, i]\n",
    "\n",
    "            p2[0] = 255 - p1[0]\n",
    "            p2[1] = 255 - p1[1]\n",
    "            p2[2] = 255 - p1[2]\n",
    "\n",
    "    cv2.imshow('src', src)\n",
    "    cv2.imshow('dst', dst)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "def color_grayscale():\n",
    "    src = cv2.imread('./img/butterfly.jpg', cv2.IMREAD_COLOR)\n",
    "\n",
    "    if src is None:\n",
    "        print('Image load failed!')\n",
    "        return\n",
    "\n",
    "    dst = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    cv2.imshow('src', src)\n",
    "    cv2.imshow('dst', dst)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "def color_split():\n",
    "    src = cv2.imread('./img/candies.png', cv2.IMREAD_COLOR)\n",
    "\n",
    "    if src is None:\n",
    "        print('Image load failed!')\n",
    "        return\n",
    "\n",
    "    # b_plane, g_plane, r_plane = cv2.split(src)\n",
    "    bgr_planes = cv2.split(src)\n",
    "\n",
    "    cv2.imshow('src', src)\n",
    "    cv2.imshow('B_plane', bgr_planes[0])\n",
    "    cv2.imshow('G_plane', bgr_planes[1])\n",
    "    cv2.imshow('R_plane', bgr_planes[2])\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    color_op()\n",
    "    color_inverse()\n",
    "    color_grayscale()\n",
    "    color_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coloreq\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "src = cv2.imread('./img/pepper.bmp', cv2.IMREAD_COLOR)\n",
    "\n",
    "if src is None:\n",
    "    print('Image load failed!')\n",
    "    sys.exit()\n",
    "\n",
    "src_ycrcb = cv2.cvtColor(src, cv2.COLOR_BGR2YCrCb)\n",
    "\n",
    "ycrcb_planes = cv2.split(src_ycrcb)\n",
    "\n",
    "ycrcb_planes=np.array(ycrcb_planes)\n",
    "\n",
    "ycrcb_planes[0] = cv2.equalizeHist(ycrcb_planes[0])\n",
    "\n",
    "dst_ycrcb = cv2.merge(ycrcb_planes)\n",
    "\n",
    "dst = cv2.cvtColor(dst_ycrcb, cv2.COLOR_YCrCb2BGR)\n",
    "\n",
    "cv2.imshow('src', src)\n",
    "cv2.imshow('dst', dst)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# TypeError: 'tuple' object does not support item assignment\n",
    "\n",
    "# solution\n",
    "# ycrcb_planes=np.array(ycrcb_planes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = cv2.imread('./img/pepper.bmp', cv2.IMREAD_COLOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_ycrcb = cv2.cvtColor(src, cv2.COLOR_BGR2YCrCb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 30, 179, 111],\n",
       "        [ 58, 186, 175],\n",
       "        [ 62, 191, 175],\n",
       "        ...,\n",
       "        [ 75, 211, 175],\n",
       "        [ 81, 216, 182],\n",
       "        [ 57, 173, 198]],\n",
       "\n",
       "       [[ 37, 189, 107],\n",
       "        [119, 179,  87],\n",
       "        [114, 182,  92],\n",
       "        ...,\n",
       "        [174, 114,  78],\n",
       "        [161, 110,  86],\n",
       "        [157,  98,  87]],\n",
       "\n",
       "       [[ 38, 191, 107],\n",
       "        [121, 174,  88],\n",
       "        [115, 178,  90],\n",
       "        ...,\n",
       "        [171, 109,  83],\n",
       "        [170, 112,  76],\n",
       "        [158,  96,  88]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 28, 174, 112],\n",
       "        [124, 130,  85],\n",
       "        [132, 131,  84],\n",
       "        ...,\n",
       "        [199, 115, 114],\n",
       "        [196, 114, 113],\n",
       "        [187, 129,  95]],\n",
       "\n",
       "       [[ 28, 174, 112],\n",
       "        [121, 143,  89],\n",
       "        [111, 139,  92],\n",
       "        ...,\n",
       "        [195, 114, 110],\n",
       "        [193, 116, 115],\n",
       "        [169, 147,  99]],\n",
       "\n",
       "       [[ 28, 174, 112],\n",
       "        [ 86, 152, 100],\n",
       "        [127, 137,  89],\n",
       "        ...,\n",
       "        [184, 115, 109],\n",
       "        [192, 113, 122],\n",
       "        [196, 129, 114]]], dtype=uint8)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_ycrcb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 30,  58,  62, ...,  75,  81,  57],\n",
       "       [ 37, 119, 114, ..., 174, 161, 157],\n",
       "       [ 38, 121, 115, ..., 171, 170, 158],\n",
       "       ...,\n",
       "       [ 28, 124, 132, ..., 199, 196, 187],\n",
       "       [ 28, 121, 111, ..., 195, 193, 169],\n",
       "       [ 28,  86, 127, ..., 184, 192, 196]], dtype=uint8)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_ycrcb[:,:,(0)]\n",
    "# 3차원 배열의 이미지 데이터라고 가정\n",
    "# [:,:] 모든 행과 모든 열을 선택한다\n",
    "# (0) 3번째 차원에서 첫 번째 채널을 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ycrcb_planes = cv2.split(src_ycrcb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 30,  58,  62, ...,  75,  81,  57],\n",
       "        [ 37, 119, 114, ..., 174, 161, 157],\n",
       "        [ 38, 121, 115, ..., 171, 170, 158],\n",
       "        ...,\n",
       "        [ 28, 124, 132, ..., 199, 196, 187],\n",
       "        [ 28, 121, 111, ..., 195, 193, 169],\n",
       "        [ 28,  86, 127, ..., 184, 192, 196]], dtype=uint8),\n",
       " array([[179, 186, 191, ..., 211, 216, 173],\n",
       "        [189, 179, 182, ..., 114, 110,  98],\n",
       "        [191, 174, 178, ..., 109, 112,  96],\n",
       "        ...,\n",
       "        [174, 130, 131, ..., 115, 114, 129],\n",
       "        [174, 143, 139, ..., 114, 116, 147],\n",
       "        [174, 152, 137, ..., 115, 113, 129]], dtype=uint8),\n",
       " array([[111, 175, 175, ..., 175, 182, 198],\n",
       "        [107,  87,  92, ...,  78,  86,  87],\n",
       "        [107,  88,  90, ...,  83,  76,  88],\n",
       "        ...,\n",
       "        [112,  85,  84, ..., 114, 113,  95],\n",
       "        [112,  89,  92, ..., 110, 115,  99],\n",
       "        [112, 100,  89, ..., 109, 122, 114]], dtype=uint8))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ycrcb_planes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 30,  58,  62, ...,  75,  81,  57],\n",
       "       [ 37, 119, 114, ..., 174, 161, 157],\n",
       "       [ 38, 121, 115, ..., 171, 170, 158],\n",
       "       ...,\n",
       "       [ 28, 124, 132, ..., 199, 196, 187],\n",
       "       [ 28, 121, 111, ..., 195, 193, 169],\n",
       "       [ 28,  86, 127, ..., 184, 192, 196]], dtype=uint8)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_ycrcb[:,:,(0)]\n",
    "# 3차원 배열의 이미지 데이터라고 가정\n",
    "# [:,:] 모든 행과 모든 열을 선택한다\n",
    "# (0) 3번째 차원에서 첫 번째 채널을 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ycrcb_planes)\n",
    "# 여기서 오류가 발생. 튜플이라서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ycrcb_planes=np.array(ycrcb_planes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ycrcb_planes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ycrcb_planes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 20,  36,  39, ...,  51,  60,  35],\n",
       "       [ 23, 126, 121, ..., 205, 183, 176],\n",
       "       [ 23, 128, 122, ..., 200, 199, 178],\n",
       "       ...,\n",
       "       [ 18, 131, 139, ..., 244, 242, 227],\n",
       "       [ 18, 128, 118, ..., 241, 238, 197],\n",
       "       [ 18,  69, 134, ..., 221, 237, 242]], dtype=uint8)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.equalizeHist(ycrcb_planes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "ycrcb_planes[0] = cv2.equalizeHist(ycrcb_planes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_ycrcb = cv2.merge(ycrcb_planes)\n",
    "dst = cv2.cvtColor(dst_ycrcb, cv2.COLOR_YCrCb2BGR)\n",
    "\n",
    "cv2.imshow('src', src)\n",
    "cv2.imshow('dst', dst)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuple error solution\n",
    "\n",
    "# 만약 **첫 번째 채널(단일 인덱스)**만을 참조하려는 것이라면,\n",
    "# (0) 대신 0을 사용해야 합니다.\n",
    "# # 올바른 예시\n",
    "# y_channel = src_ycrcb[:, :, 0]  # 첫 번째 채널만 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:868: error: (-215:Assertion failed) trackbar in function 'cv::getTrackbarPos'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 9\u001b[0m, in \u001b[0;36mon_hue_changed\u001b[1;34m(_)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_hue_changed\u001b[39m(_\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m      8\u001b[0m     lower_hue \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mgetTrackbarPos(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLower Hue\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmask\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m     upper_hue \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mgetTrackbarPos(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUpper Hue\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmask\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m# 트랙 바는 일정 범위 내의 값을 변경할 때 사용하며,\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m# 적절한 임곗값을 찾거나 변경하기 위해 사용합니다.\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     lowerb \u001b[38;5;241m=\u001b[39m (lower_hue, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:868: error: (-215:Assertion failed) trackbar in function 'cv::getTrackbarPos'\n"
     ]
    }
   ],
   "source": [
    "# inrange\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "def on_hue_changed(_=None):\n",
    "    lower_hue = cv2.getTrackbarPos('Lower Hue', 'mask')\n",
    "    upper_hue = cv2.getTrackbarPos('Upper Hue', 'mask')\n",
    "    # 트랙 바는 일정 범위 내의 값을 변경할 때 사용하며,\n",
    "    # 적절한 임곗값을 찾거나 변경하기 위해 사용합니다.\n",
    "\n",
    "    lowerb = (lower_hue, 100, 0)\n",
    "    upperb = (upper_hue, 255, 255)\n",
    "    mask = cv2.inRange(src_hsv, lowerb, upperb)\n",
    "\n",
    "    cv2.imshow('mask', mask)\n",
    "\n",
    "\n",
    "def main():\n",
    "    global src_hsv\n",
    "\n",
    "    src = cv2.imread('./img/candies.png', cv2.IMREAD_COLOR)\n",
    "\n",
    "    if src is None:\n",
    "        print('Image load failed!')\n",
    "        return\n",
    "\n",
    "    src_hsv = cv2.cvtColor(src, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    cv2.imshow('src', src)\n",
    "\n",
    "    cv2.namedWindow('mask')\n",
    "    cv2.createTrackbar('Lower Hue', 'mask', 40, 179, on_hue_changed)\n",
    "    cv2.createTrackbar('Upper Hue', 'mask', 80, 179, on_hue_changed)\n",
    "    on_hue_changed(0)\n",
    "\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n",
    "# 트랙바를 통해 조절하면서 특정 색상만을 확인"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backproj\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Calculate CrCb histogram from a reference image\n",
    "\n",
    "ref = cv2.imread('./img/ref.png', cv2.IMREAD_COLOR)\n",
    "mask = cv2.imread('./img/mask.bmp', cv2.IMREAD_GRAYSCALE)\n",
    "ref_ycrcb = cv2.cvtColor(ref, cv2.COLOR_BGR2YCrCb)\n",
    "\n",
    "channels = [1, 2]\n",
    "cr_bins = 128\n",
    "cb_bins = 128\n",
    "histSize = [cr_bins, cb_bins]\n",
    "cr_range = [0, 256]\n",
    "cb_range = [0, 256]\n",
    "ranges = cr_range + cb_range\n",
    "\n",
    "hist = cv2.calcHist([ref_ycrcb], channels, mask, histSize, ranges)\n",
    "\n",
    "# Apply histogram backprojection to an input image\n",
    "\n",
    "src = cv2.imread('./img/kids.png', cv2.IMREAD_COLOR)\n",
    "src_ycrcb = cv2.cvtColor(src, cv2.COLOR_BGR2YCrCb)\n",
    "\n",
    "backproj = cv2.calcBackProject([src_ycrcb], channels, hist, ranges, 1)\n",
    "\n",
    "cv2.imshow('src', src)\n",
    "cv2.imshow('backproj', backproj)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prmldl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
