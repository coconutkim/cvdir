{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 60\u001b[0m\n\u001b[0;32m     57\u001b[0m dx, dy \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m50\u001b[39m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# 중앙 기준으로 반사 적용\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m result_img \u001b[38;5;241m=\u001b[39m \u001b[43mwarp_affine_with_center_reflect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# 결과 이미지 저장 또는 표시\u001b[39;00m\n\u001b[0;32m     63\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimwrite(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransformed_image.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m, result_img)\n",
      "Cell \u001b[1;32mIn[2], line 11\u001b[0m, in \u001b[0;36mwarp_affine_with_center_reflect\u001b[1;34m(img, mtrx, dx, dy)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwarp_affine_with_center_reflect\u001b[39m(img, mtrx, dx, dy):\n\u001b[1;32m---> 11\u001b[0m     rows, cols \u001b[38;5;241m=\u001b[39m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m[:\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m# 이미지 중앙 좌표\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     center \u001b[38;5;241m=\u001b[39m (cols \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m, rows \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# translate\n",
    "\n",
    "# 수행 목록\n",
    "# 중심으로 기준으로 반사\n",
    "# 반사된 것의 색을 반전\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def warp_affine_with_center_reflect(img, mtrx, dx, dy):\n",
    "    rows, cols = img.shape[:2]\n",
    "\n",
    "    # 이미지 중앙 좌표\n",
    "    center = (cols / 2, rows / 2)\n",
    "    \n",
    "    # 이동 매트릭스\n",
    "    move_mtrx = np.float32([\n",
    "        [1, 0, dx],\n",
    "        [0, 1, dy]\n",
    "    ])\n",
    "    \n",
    "    # 중심 이동 매트릭스 (중심을 원점으로 이동)\n",
    "    center_to_origin = np.float32([\n",
    "        [1, 0, -center[0]],\n",
    "        [0, 1, -center[1]]\n",
    "    ])\n",
    "    \n",
    "    # 원점에서 중심으로 이동\n",
    "    origin_to_center = np.float32([\n",
    "        [1, 0, center[0]],\n",
    "        [0, 1, center[1]]\n",
    "    ])\n",
    "    \n",
    "    # 이동 후 반사 매트릭스 (중앙을 기준으로 반사)\n",
    "    # 반사는 x축 기준으로 진행\n",
    "    reflect_mtrx = np.float32([\n",
    "        [-1, 0, 2 * center[0]],\n",
    "        [0, 1, 0]\n",
    "    ])\n",
    "    \n",
    "    # 반사 후 이동 매트릭스 (원점에서 이동)\n",
    "    reflect_mtrx = np.dot(reflect_mtrx, move_mtrx)\n",
    "    \n",
    "    # 최종 매트릭스는 중심 이동 -> 반사 -> 원위치 이동\n",
    "    final_mtrx = np.dot(origin_to_center, np.dot(reflect_mtrx, center_to_origin))\n",
    "    \n",
    "    # 이미지 변환\n",
    "    transformed_img = cv2.warpAffine(img, final_mtrx[:2], (cols + dx, rows + dy), \n",
    "                                     flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT)\n",
    "    \n",
    "    return transformed_img\n",
    "\n",
    "# 이미지 불러오기\n",
    "img = cv2.imread('your_image.jpg')\n",
    "\n",
    "# 이동 변환 정도\n",
    "dx, dy = 50, 50\n",
    "\n",
    "# 중앙 기준으로 반사 적용\n",
    "result_img = warp_affine_with_center_reflect(img, None, dx, dy)\n",
    "\n",
    "# 결과 이미지 저장 또는 표시\n",
    "cv2.imwrite('transformed_image.jpg', result_img)\n",
    "\n",
    "\n",
    "# ---④ 탈락된 외곽 픽셀을 원본을 반사 시켜서 보정\n",
    "dst3 = cv2.warpAffine(img, mtrx, (cols+dx, rows+dy), None, \\\n",
    "                                cv2.INTER_LINEAR, cv2.BORDER_REFLECT)\n",
    "\n",
    "# cv2.imshow('original', img)\n",
    "# cv2.imshow('trans',dst)\n",
    "# cv2.imshow('BORDER_CONSTATNT', dst2)\n",
    "cv2.imshow('BORDER_FEFLECT', dst3)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale_matrix\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('../img/fish.jpg')\n",
    "height, width = img.shape[:2]\n",
    "\n",
    "# --① 0.5배 축소 변환 행렬\n",
    "m_small = np.float32([[0.5, 0, 0],\n",
    "                       [0, 0.5,0]])  \n",
    "# --② 2배 확대 변환 행렬\n",
    "m_big = np.float32([[2, 0, 0],\n",
    "                     [0, 2, 0]])  \n",
    "\n",
    "# 선형 보간법(linear interpolation)\n",
    "# 끝점의 값이 주어졌을 때\n",
    "# 그 사이에 위치한 값을 추정하기 위하여\n",
    "# 직선 거리에 따라 선형적으로 계산하는 방법이다\n",
    "\n",
    "# --③ 보간법 적용 없이 확대 축소\n",
    "dst1 = cv2.warpAffine(img, m_small, (int(height*0.5), int(width*0.5)))\n",
    "dst2 = cv2.warpAffine(img, m_big, (int(height*2), int(width*2)))\n",
    "\n",
    "# --④ 보간법 적용한 확대 축소\n",
    "dst3 = cv2.warpAffine(img, m_small, (int(height*0.5), int(width*0.5)), \\\n",
    "                        None, cv2.INTER_AREA)\n",
    "dst4 = cv2.warpAffine(img, m_big, (int(height*2), int(width*2)), \\\n",
    "                        None, cv2.INTER_CUBIC)\n",
    "\n",
    "# 결과 출력\n",
    "cv2.imshow(\"original\", img)\n",
    "cv2.imshow(\"small\", dst1)\n",
    "cv2.imshow(\"big\", dst2)\n",
    "cv2.imshow(\"small INTER_AREA\", dst3)\n",
    "cv2.imshow(\"big INTER_CUBIC\", dst4)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:973: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 73\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# cv2.imshow(\"45\", img45)\u001b[39;00m\n\u001b[0;32m     72\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m45\u001b[39m\u001b[38;5;124m\"\u001b[39m, roatate)\n\u001b[1;32m---> 73\u001b[0m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m90\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrotate_big_edit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m cv2\u001b[38;5;241m.\u001b[39mwaitKey()\n\u001b[0;32m     75\u001b[0m cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:973: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# rotate_getmatrix\n",
    "\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread(r'C:\\ex\\cvdir\\insightbook.opencv_project_python-master\\img\\blackcat.jpg')\n",
    "rows,cols = img.shape[0:2]\n",
    "\n",
    "#---① 회전을 위한 변환 행렬 구하기\n",
    "# 회전축:중앙, 각도:45, 배율:0.5\n",
    "m45 = cv2.getRotationMatrix2D((rows/2,cols/2),90,1) \n",
    "m45 = cv2.getRotationMatrix2D((cols/2,rows/2),90,1) \n",
    "# 회전축:중앙, 각도:90, 배율:1.5\n",
    "m90 = cv2.getRotationMatrix2D((rows/2,cols/2),90,1.5) \n",
    "\n",
    "def rotate_image(img, angle, scale):\n",
    "    rows, cols = img.shape[:2]\n",
    "    \n",
    "    # 회전 행렬 생성, 회전축을 이미지 중앙으로 설정\n",
    "    mtrx = cv2.getRotationMatrix2D((cols / 2, rows / 2), angle, scale)\n",
    "    \n",
    "    # 회전된 이미지의 새로운 크기 계산\n",
    "    cos_theta = np.abs(mtrx[0, 0])\n",
    "    sin_theta = np.abs(mtrx[0, 1])\n",
    "    \n",
    "    # 회전 후 이미지 크기\n",
    "    new_cols = int(rows * sin_theta + cols * cos_theta)\n",
    "    new_rows = int(rows * cos_theta + cols * sin_theta)\n",
    "    \n",
    "    # 새로운 회전 행렬에 대한 이동 조정\n",
    "    mtrx[0, 2] += (new_cols - cols) / 2\n",
    "    mtrx[1, 2] += (new_rows - rows) / 2\n",
    "    \n",
    "    # 회전 이미지 생성\n",
    "    rotated_img = cv2.warpAffine(img, mtrx, (new_cols, new_rows), flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT, borderValue=(0,0,0))\n",
    "    return rotated_img\n",
    "\n",
    "def resize_and_crop_image(bg_img, overlay_img, crop_x_offset=0, crop_y_offset=0):\n",
    "    bg_rows, bg_cols = bg_img.shape[:2]\n",
    "    ol_rows, ol_cols = overlay_img.shape[:2]\n",
    "\n",
    "    # 확대된 이미지가 원본 이미지의 크기에 맞게 크롭\n",
    "    if ol_rows > bg_rows or ol_cols > bg_cols:\n",
    "        scale_x = ol_cols / bg_cols\n",
    "        scale_y = ol_rows / bg_rows\n",
    "        scale = max(scale_x, scale_y)\n",
    "        \n",
    "        new_ol_cols = int(bg_cols * scale)\n",
    "        new_ol_rows = int(bg_rows * scale)\n",
    "        \n",
    "        start_x = max((new_ol_cols - ol_cols) // 2 + crop_x_offset, 0)\n",
    "        start_y = max((new_ol_rows - ol_rows) // 2 + crop_y_offset, 0)\n",
    "        \n",
    "        # 크롭\n",
    "        cropped_overlay_img = overlay_img[start_y:start_y + bg_rows, start_x:start_x + bg_cols]\n",
    "    else:\n",
    "        cropped_overlay_img = overlay_img\n",
    "    \n",
    "    return cropped_overlay_img\n",
    "\n",
    "\n",
    "#---② 변환 행렬 적용\n",
    "# img45 = cv2.warpAffine(img, m45,(rows,cols))\n",
    "# img90 = cv2.warpAffine(img, m90,(rows,cols))\n",
    "\n",
    "roatate=rotate_image(img, 90, 1)\n",
    "roatate_big=rotate_image(img, 90, 1.8)\n",
    "rotate_big_edit=resize_and_crop_image(roatate, roatate_big, crop_x_offset=100, crop_y_offset=0)\n",
    "\n",
    "#---③ 결과 출력\n",
    "cv2.imshow('origin',img)\n",
    "# cv2.imshow(\"45\", img45)\n",
    "cv2.imshow(\"45\", roatate)\n",
    "cv2.imshow(\"90\", rotate_big_edit)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (143,143,3) (143,143,3) (181,181,3) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 71\u001b[0m\n\u001b[0;32m     68\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 71\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[24], line 60\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     57\u001b[0m img90 \u001b[38;5;241m=\u001b[39m rotate_image(img, angle90, scale90)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# 원본 이미지 위에 회전된 이미지를 오버레이\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m overlay45_img \u001b[38;5;241m=\u001b[39m \u001b[43moverlay_image_on_background\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg45\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m overlay90_img \u001b[38;5;241m=\u001b[39m overlay_image_on_background(img, img90)\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# 결과 출력\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[24], line 40\u001b[0m, in \u001b[0;36moverlay_image_on_background\u001b[1;34m(bg_img, overlay_img)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# 회전된 이미지를 원본 이미지의 중앙에 배치\u001b[39;00m\n\u001b[0;32m     39\u001b[0m result_img \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcopy(bg_img)\n\u001b[1;32m---> 40\u001b[0m result_img[y_start:y_end, x_start:x_end] \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43moverlay_img\u001b[49m\u001b[43m[\u001b[49m\u001b[43my_start\u001b[49m\u001b[43m:\u001b[49m\u001b[43my_end\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_start\u001b[49m\u001b[43m:\u001b[49m\u001b[43mx_end\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverlay_img\u001b[49m\u001b[43m[\u001b[49m\u001b[43my_start\u001b[49m\u001b[43m:\u001b[49m\u001b[43my_end\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_start\u001b[49m\u001b[43m:\u001b[49m\u001b[43mx_end\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult_img\u001b[49m\u001b[43m[\u001b[49m\u001b[43my_start\u001b[49m\u001b[43m:\u001b[49m\u001b[43my_end\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_start\u001b[49m\u001b[43m:\u001b[49m\u001b[43mx_end\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result_img\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mwhere\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (143,143,3) (143,143,3) (181,181,3) "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 29\u001b[0m\n\u001b[0;32m     26\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRotated Image\u001b[39m\u001b[38;5;124m'\u001b[39m, rotated_img)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# 키 입력 대기 (50ms)\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitKey\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m0xFF\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m27\u001b[39m:  \u001b[38;5;66;03m# ESC 키를 누르면 종료\u001b[39;00m\n\u001b[0;32m     30\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# 이미지 불러오기\n",
    "img = cv2.imread(r'C:\\ex\\cvdir\\insightbook.opencv_project_python-master\\img\\gaussian_noise.jpg')\n",
    "\n",
    "# 이미지 크기\n",
    "rows, cols = img.shape[:2]\n",
    "\n",
    "# 회전 각도 및 배율 파라미터\n",
    "angle_step = 5      # 각 프레임마다 회전할 각도\n",
    "scale_initial = 0.5 # 초기 배율\n",
    "scale_step = 0.01   # 배율 변화량\n",
    "\n",
    "# 무한 루프를 통해 계속 이미지 회전\n",
    "while True:\n",
    "    for angle in range(0, 360, angle_step):\n",
    "        # 회전 행렬 계산\n",
    "        scale = scale_initial + (scale_step * angle) % 1\n",
    "        mtrx = cv2.getRotationMatrix2D((cols / 2, rows / 2), angle, scale)\n",
    "        \n",
    "        # 이미지 회전 적용\n",
    "        rotated_img = cv2.warpAffine(img, mtrx, (cols, rows), flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT)\n",
    "        \n",
    "        # 결과 이미지 표시\n",
    "        cv2.imshow('Rotated Image', rotated_img)\n",
    "        \n",
    "        # 키 입력 대기 (50ms)\n",
    "        if cv2.waitKey(50) & 0xFF == 27:  # ESC 키를 누르면 종료\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mldltest1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
